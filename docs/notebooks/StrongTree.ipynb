{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from odtlearn.StrongTree import StrongTreeClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Strong Classification Trees\n",
    "This document aims to show how to use the `StrongTreeClassifier` to fit optimal strong classification trees. We begin with the standard use case, walking through parameter choices and method details, and then provide a small example on a real-world data set.\n",
    "\n",
    "## `StrongTreeClassifier`: the basics\n",
    "\n",
    "StrongTree is an MIO formulation for learning optimal *balanced* classification tress of a given depth, i.e., trees wherein the distance between all nodes where a prediction is made, and the root node is equal to the tree depth. This MIO formulation relies on the observation that once the structure of the tree is fixed, determining whether a datapoint is correctly classified or not reduces to checking whether the datapoint can, based on its feature and label, flow from the root of the tree to a leaf where the prediction made matches its label. For a complete treatment of StrongTrees, see our paper [Aghaei et al., 2021](https://arxiv.org/abs/2103.15965).\n",
    "\n",
    "A key step towards our flow-based MIO formulation of the problem consists of converting the decision tree of fixed depth that we wish to train to a directed acyclic graph where all arcs are directed from the root of the tree to the leaves:\n",
    "\n",
    "![](../_static/img/strongTree_graph.png)\n",
    "\n",
    "This modification of the tree enables us to think of the decision tree as a *directed acyclic graph with a single source and sink node*. Datapoints *flow* from the source to sink through a single path and only reach the sink if they are correctly classified.\n",
    "\n",
    "**abbreviated version of problem formulation here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Example 1: varying `depth` and `_lambda`\n",
    "We start with a simple example and investigate different parameter combinations to provide intuition on how they affect the structure of the tree.\n",
    "\n",
    "First we generate the data for our example. The diagram within the code block shows the expected structure of the fitted optimal decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    X2\n",
    "    |               |\n",
    "    |               |\n",
    "    1    + +        |    -\n",
    "    |               |   \n",
    "    |---------------|-------------\n",
    "    |               |\n",
    "    0    - - - -    |    + + +\n",
    "    |    - - -      |\n",
    "    |______0________|_______1_______X1\n",
    "'''\n",
    "X = np.array([[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],\n",
    "            [1,0],[1,0],[1,0],\n",
    "            [1,1],\n",
    "            [0,1],[0,1]])\n",
    "\n",
    "y = np.array([0,0,0,0,0,0,0,\n",
    "            1,1,1,\n",
    "            0,\n",
    "            1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree with `depth = 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stcl = StrongTreeClassifier(\n",
    "        depth = 1, \n",
    "        time_limit = 60,\n",
    "        _lambda = 0.51,\n",
    "        benders_oct= True, \n",
    "        num_threads=None, \n",
    "        obj_mode = 'acc'\n",
    "    )\n",
    "stcl.fit(X, y, verbose = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = stcl.predict(X)\n",
    "print(f'In-sample accuracy is {np.sum(predictions==y)/y.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also provide two different ways of visualizing the structure of the tree. The first method prints the structure of the tree in the console:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stcl.print_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second method plots the structure of the tree using `matplotlib`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stcl.plot_tree()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree with `depth = 2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stcl = StrongTreeClassifier(\n",
    "        depth = 2, \n",
    "        time_limit = 60,\n",
    "        _lambda = 0.51,\n",
    "        benders_oct= True, \n",
    "        num_threads=None, \n",
    "        obj_mode = 'acc'\n",
    "    )\n",
    "stcl.fit(X, y, verbose = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = stcl.predict(X)\n",
    "print(f'In-sample accuracy is {np.sum(predictions==y)/y.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stcl.plot_tree()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree with `depth=2` and positive `_lambda` ([0,0.51])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stcl = StrongTreeClassifier(\n",
    "        depth = 2, \n",
    "        time_limit = 60,\n",
    "        _lambda = 0.51,\n",
    "        benders_oct= True, \n",
    "        num_threads=None, \n",
    "        obj_mode = 'acc'\n",
    "    )\n",
    "stcl.fit(X, y, verbose = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = stcl.predict(X)\n",
    "print(f'In-sample accuracy is {np.sum(predictions==y)/y.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stcl.plot_tree()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choice of Objective\n",
    "\n",
    "For the StrongTree class, we have two options for the objective function. We can either maximize the classification accuracy or the balanced accuracy. \n",
    "\n",
    "\n",
    "$$\\text{max} \\sum_{i \\in \\mathcal I}\\sum_{n \\in \\mathcal N \\cup \\mathcal L} z^i_{n,t} \\quad \\text{(accuracy)}$$\n",
    "\n",
    "$$\\text{max} \\frac{1}{|\\mathcal K|}\\sum_{k \\in \\mathcal K}\\frac{1}{ |\\{i \\in \\mathcal I: y^i=k\\}|}\\sum_{i \\in \\mathcal I: y^i=k}\\sum_{n \\in \\mathcal N \\cup \\mathcal L} z^i_{n,t} \\quad \\text{(balanced accuracy)}$$\n",
    "\n",
    "   \n",
    "The balanced accuracy can be helpful in the case of imbalanced datasets.\n",
    "    \n",
    "- A dataset is called imbalanced when the class distribution is not uniform, i.e., when the number of datapoints in each class varies significantly from class to class.\n",
    "    \n",
    "- In imbalanced datasets, predicting the majority class for all datapoints results in high accuracy, and thus decision trees that maximize prediction accuracy without accounting for the imbalanced nature of the data perform poorly on the minority class.\n",
    "\n",
    "- Imbalanced datasets occur in many important domains, e.g., the suicide prevention problem!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Example 2: different objective functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    X2\n",
    "    |               | \n",
    "    |               |\n",
    "    1    + - -      |    -\n",
    "    |               |   \n",
    "    |---------------|--------------\n",
    "    |               |\n",
    "    0    - - - +    |    - - -\n",
    "    |    - - - -    |\n",
    "    |______0________|_______1_______X1\n",
    "'''\n",
    "X = np.array([[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],\n",
    "              [1,0],[1,0],[1,0],\n",
    "              [1,1],\n",
    "              [0,1],[0,1],[0,1]])\n",
    "y = np.array([0,0,0,0,0,0,0,1,\n",
    "              0,0,0,\n",
    "              0,\n",
    "              1,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree with classification accuracy objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stcl_acc = StrongTreeClassifier(\n",
    "        depth = 2, \n",
    "        time_limit = 60,\n",
    "        _lambda = 0,\n",
    "        benders_oct= False, \n",
    "        num_threads=None, \n",
    "        obj_mode = 'acc'\n",
    "    )\n",
    "stcl_acc.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stcl_acc.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stcl_acc.plot_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree with balanced classification accuracy objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stcl_balance = StrongTreeClassifier(\n",
    "        depth = 2, \n",
    "        time_limit = 60,\n",
    "        _lambda = 0,\n",
    "        benders_oct= False, \n",
    "        num_threads=None, \n",
    "        obj_mode = 'balance'\n",
    "    )\n",
    "stcl_balance.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stcl_balance.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stcl_balance.plot_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "Aghaei, S., GÃ³mez, A., & Vayanos, P. (2021). Strong optimal classification trees. arXiv preprint arXiv:2103.15965. [[arxiv](https://arxiv.org/abs/2103.15965)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dfaf93ad87348b32221474fd3c800e01f580d105683f49be3d64b58d8896a56c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
